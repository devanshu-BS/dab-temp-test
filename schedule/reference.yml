# The main job for prod_replica_ingestion.
resources:
  jobs:
    ## do not change the key names here
    automated_jobs:
      name: job_name_${bundle.target}
      schedule:
        quartz_cron_expression: "0 0 0 0 0 ?"
        timezone_id: Asia/Kolkata
        pause_status: PAUSED

      job_clusters:
        - job_cluster_key: job-cluster-name
          new_cluster:
            apply_policy_default_values: true
            spark_version: ${var.cluster_spark_version}
            policy_id: ${var.cluster_policy_id_job_compute}
            node_type_id: m5d.large
            driver_node_type_id: m5d.large
            spark_conf:
              "spark.hadoop.fs.s3a.assumed.role.arn": ${var.datalake_readonly_arn}
              "spark.sql.parquet.compression.codec": "zstd"
              "parquet.compression.codec.zstd.level": "9"
            aws_attributes:
              "instance_profile_arn": ${var.instance_profile_arn}
              "zone_id": ${var.zone_id}
            data_security_mode: "SINGLE_USER"
            enable_elastic_disk: true
            autoscale:
              min_workers: 1
              max_workers: 2

      tasks:
        - task_key: battery_movement
          notebook_task:
            notebook_path: notebooks/analytics_battery_movement
            source: GIT
          job_cluster_key: job-cluster-name



      git_source:
        git_url: https://github.com/devanshu-BS/dab-temp-test.git
        git_provider: gitHub
        git_branch: ${var.git_branch} 
